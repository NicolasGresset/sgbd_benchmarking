{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9a9acb-eb84-4eb4-bd53-a5b3727e6cb2",
   "metadata": {},
   "source": [
    "# SDB Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf435d",
   "metadata": {},
   "source": [
    "## Choices\n",
    "\n",
    "We took several parameters into account in order to provide unbiased and reproductible results. We present them in the next section.\n",
    "\n",
    "### Time measurement\n",
    "\n",
    "In order to measure accurately the time taken for a database CRUD operation to complete, we need to measure the duration between the moment the command is called and the moment it returns (both postgres and cassandra python API functions returns synchronuously). In addition, we measure time by several (100) batches of 100 measurements. This allows to plot the distribution of several latencies AND have precise enough measurements. \n",
    "Besides, we use the time.perf_counter function from the time module which has the best accuracy for measuring time in Python.Finally, we also clean the built-in garbage collector of Python before each measurement to ensure consistent behaviour.\n",
    "\n",
    "### Reproducibility\n",
    "\n",
    "Most of the queries we generate are random to limit bias in the analysis : one database system could perform surprisingly well for a specific data. Using random queries reduce such a bias. Therefore, we chose to write our queries once to a file and to perform them by reading directly the file instead of generating news random datas at each runtime execution. This let us make precise commentaries on the actual data we have observed which is the very same data you will see being displayed.\n",
    "\n",
    "### Displaying results\n",
    "\n",
    "We choose to display results with histograms to overview the whole frequency distribution rather than only the mean or the standard deviation. When needed, both means are represented alongside to better compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6755ea-1fc6-4488-979f-b962c3d891c3",
   "metadata": {},
   "source": [
    "## Initialise cassandra database\n",
    "\n",
    "If the following cells raise a `ConnexionRefuseError`, it may be because of the Cassandra database didn't finished to initialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c641e7-dfa0-408d-92fc-947b5cfa7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, gc, time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import BatchStatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355228ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f2594518820>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(120)\n",
    "\n",
    "cluster = Cluster(['cassandra'])\n",
    "session = cluster.connect()\n",
    "\n",
    "# Create a keyspace and table\n",
    "session.execute(\"\"\"CREATE KEYSPACE IF NOT EXISTS benchmarking WITH REPLICATION = \n",
    "{ 'class' : 'SimpleStrategy', 'replication_factor' : '1' }\"\"\")\n",
    "session.execute(\"\"\"CREATE TABLE IF NOT EXISTS benchmarking.bitcoin_addresses (BITCOIN_ADDRESS text, ACCOUNT text, \n",
    "IP_ADDRESS text, COUNTY text, COUNTRY_CODE text, DATABASE_COLUMN_TYPE text, PRIMARY KEY \n",
    "(BITCOIN_ADDRESS))\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07cd67",
   "metadata": {},
   "source": [
    "## Import Data into cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22922ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "with open(\"/home/data.csv\", 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    insert_query = session.prepare(\"\"\"\n",
    "INSERT INTO benchmarking.bitcoin_addresses (BITCOIN_ADDRESS, ACCOUNT, IP_ADDRESS, COUNTY, COUNTRY_CODE, DATABASE_COLUMN_TYPE)\n",
    "VALUES (?, ?, ?, ?, ?, ?)\n",
    "\"\"\")\n",
    "    cassandra_times_import = np.empty(100)\n",
    "\n",
    "    for sample in range(100):\n",
    "        batch = BatchStatement()\n",
    "\n",
    "        for i in range(1000):\n",
    "            row = next(reader)\n",
    "            session.execute(insert_query, (\n",
    "                row['BITCOIN_ADDRESS'],\n",
    "                row['ACCOUNT'],\n",
    "                row['IP_ADDRESS'],\n",
    "                row['COUNTY'],\n",
    "                row['COUNTRY_CODE'],\n",
    "                row['DATABASE_COLUMN_TYPE']\n",
    "            ))\n",
    "\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        session.execute(batch)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_times_import[sample] = (end_time - start_time)\n",
    "        print(sample, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f767c",
   "metadata": {},
   "source": [
    "## Initialise PostrgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd180c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database and set up the table\n",
    "import psycopg2, random, string\n",
    "from psycopg2 import sql\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    dbname=\"postgresDB\", \n",
    "    user=\"user\", \n",
    "    password=\"tprli\", \n",
    "    host=\"postgres\",  # Or use your database host if it's not local\n",
    "    port=\"5432\"  # Default PostgreSQL port\n",
    ")\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS bitcoin_addresses;\")\n",
    "\n",
    "# Step 2: Create the table in PostgreSQL if it doesn't exist\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE bitcoin_addresses (\n",
    "    bitcoin_address VARCHAR(34) NOT NULL, -- Bitcoin addresses are usually 26-35 characters\n",
    "    account VARCHAR(20),                 -- Account numbers, max length derived from the example\n",
    "    ip_address VARCHAR(15),              -- IPv4 addresses, formatted as strings\n",
    "    county VARCHAR(50),                  -- County names, variable length\n",
    "    country_code CHAR(2),                -- Two-letter country codes\n",
    "    database_column_type VARCHAR(50),   -- Describes column type as text (e.g., mediumint, float),\n",
    "    PRIMARY KEY (bitcoin_address)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12183e33",
   "metadata": {},
   "source": [
    "## import data into PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_times_import = np.empty(100)\n",
    "with open('/home/data.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip the header row\n",
    "\n",
    "\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO bitcoin_addresses (bitcoin_address, account, ip_address, county, country_code, database_column_type) VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    for i in range(100):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "        for j in range(1000):\n",
    "            cursor.execute(insert_query, next(reader))\n",
    "        end_time = time.perf_counter()\n",
    "        postgres_times_import[i] = (end_time - start_time)\n",
    "        print(i, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be28ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_bin = min(cassandra_times_import.min(), postgres_times_import.min())\n",
    "max_bin = max(cassandra_times_import.max(), postgres_times_import.max())\n",
    "bins = np.linspace(min_bin, max_bin, 200)  # 20 bins entre les valeurs min et max\n",
    "\n",
    "# Création de l'histogramme avec des bornes communes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cassandra_times_import, bins=bins, alpha=0.7, label='Cassandra', color='blue')\n",
    "plt.hist(postgres_times_import, bins=bins, alpha=0.7, label='Postgresql', color='orange')\n",
    "\n",
    "# Ajout des légendes et des titres\n",
    "plt.title('Histogram of import times with 2 databases systems', fontsize=16)\n",
    "plt.xlabel('SGBD Systems', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "moyenne1 = np.mean(cassandra_times_import)\n",
    "moyenne2 = np.mean(postgres_times_import)\n",
    "\n",
    "labels = ['Cassandra', 'PostgreSQL']\n",
    "moyennes = [moyenne1, moyenne2]\n",
    "\n",
    "# Création du graphique en barres\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, moyennes, color=['blue', 'orange'], alpha=0.7)\n",
    "\n",
    "# Ajout des annotations\n",
    "for i, moyenne in enumerate(moyennes):\n",
    "    plt.text(i, moyenne + 1, f'{moyenne:.8f}', ha='center', fontsize=12)\n",
    "\n",
    "# Ajout des titres et légendes\n",
    "plt.title('Mean of import durations', fontsize=16)\n",
    "plt.ylabel('Mean of import durations', fontsize=14)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb664d",
   "metadata": {},
   "source": [
    "## Requests Generation\n",
    "\n",
    "Generation of randomized queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Generate random requests\n",
    "simulated_values = {\n",
    "    'BITCOIN_ADDRESS': lambda: f\"'{''.join(random.choices('ABCDEFGHJKLMNPQRSTUVWXYZ123456789', k=32))}'\",\n",
    "    'ACCOUNT': lambda: f\"'{random.randint(10000000, 99999999)}'\",\n",
    "    'IP_ADDRESS': lambda: f\"'{random.randint(1, 255)}.{random.randint(0, 255)}.{random.randint(0, 255)}.{random.randint(1, 255)}'\",\n",
    "    'COUNTY': lambda: f\"'{random.choice(['Buckinghamshire', 'Avon', 'Cambridgeshire', 'Bedfordshire', 'Borders'])}'\",\n",
    "    'COUNTRY_CODE': lambda: f\"'{random.choice('ABCDEFGHJKLMNPQRSTUVWXYZ')}{random.choice('ABCDEFGHJKLMNPQRSTUVWXYZ')}'\",\n",
    "    'DATABASE_COLUMN_TYPE': lambda: f\"'{random.choice(['float', 'point', 'int', 'serial', 'varchar', 'blob', 'timestamp'])}'\"\n",
    "}\n",
    "def generate_random_select_primary_key(table_name, primary_key, set_of_primary_key_values):\n",
    "    primary_key_value = random.choice(set_of_primary_key_values)\n",
    "\n",
    "    select_query = f\"SELECT * FROM {table_name} WHERE {primary_key} = '{primary_key_value}'\"\n",
    "    return select_query\n",
    "\n",
    "def generate_random_select_conditions(tables_name, column_names):\n",
    "    column = random.choice(column_names)\n",
    "\n",
    "    value = simulated_values[column]()  # Générer une valeur simulée pour la colonne\n",
    "    where_clause = f\"WHERE {column} = {value}\"\n",
    "\n",
    "    select_queries = {}\n",
    "    for table in tables_name:\n",
    "        select_queries[table] = f\"SELECT {column} FROM {table} {where_clause}\"\n",
    "    return select_queries\n",
    "\n",
    "def generate_random_update_query(table_name, column_names, primary_key, set_of_primary_key_values):\n",
    "    num_updates = random.randint(1,3)\n",
    "    columns_to_update = random.sample(column_names, num_updates)\n",
    "    update_values = [f\"{col} = {simulated_values[col]()}\" for col in columns_to_update]\n",
    "\n",
    "    primary_key_value = random.choice(set_of_primary_key_values)\n",
    "\n",
    "    update_query = f\"UPDATE {table_name} SET {', '.join(update_values)} WHERE {primary_key} = '{primary_key_value}'\"\n",
    "    return update_query\n",
    "\n",
    "def generate_random_delete_query(table_name, primary_key, set_of_primary_key_values):\n",
    "    primary_key_value = random.choice(set_of_primary_key_values)\n",
    "\n",
    "    delete_query = f\"DELETE FROM {table_name} WHERE {primary_key} = '{primary_key_value}'\"\n",
    "    return delete_query\n",
    "\n",
    "table = \"bitcoin_addresses\"\n",
    "table_indexed = \"bitcoin_addresses_indexed\"\n",
    "table_not_indexed = \"bitcoin_addresses_not_indexed\"\n",
    "conditions_column = ['COUNTY', 'COUNTRY_CODE','DATABASE_COLUMN_TYPE']\n",
    "update_column = ['ACCOUNT', 'IP_ADDRESS', 'COUNTY', 'COUNTRY_CODE', 'DATABASE_COLUMN_TYPE']\n",
    "primary_key = 'BITCOIN_ADDRESS'\n",
    "set_of_key = []\n",
    "rows = session.execute(\"SELECT BITCOIN_ADDRESS FROM benchmarking.bitcoin_addresses\")\n",
    "for a in rows:\n",
    "    set_of_key.append(a[0])\n",
    "\n",
    "# Generate Select queries to match primary key\n",
    "with open(\"select_primary_key.sql\", \"w\") as f:\n",
    "    for i in range(10000):\n",
    "        f.write(generate_random_select_primary_key(table, primary_key, set_of_key))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "# Generate Select with conditions queries\n",
    "with  open(\"select_conditions_not_indexed.sql\", \"w\") as f, open(\"select_conditions_indexed.sql\", \"w\") as f_index_table, open(\"select_conditions_postgre.sql\", \"w\") as f_postgre:\n",
    "    for i in range(100):\n",
    "        queries = generate_random_select_conditions([table_not_indexed, table_indexed, table], conditions_column)\n",
    "        f.write(queries[table_not_indexed])\n",
    "        f.write(\"\\n\")\n",
    "        f_index_table.write(queries[table_indexed])\n",
    "        f_index_table.write(\"\\n\")\n",
    "        f_postgre.write(queries[table])\n",
    "        f_postgre.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "# Generate Update queries\n",
    "with open(\"update.sql\", \"w\") as f:\n",
    "    for i in range(10000):\n",
    "        f.write(generate_random_update_query(table, update_column, primary_key, set_of_key))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "# Generate Delete queries\n",
    "with open(\"delete.sql\", \"w\") as f:\n",
    "    for i in range(10000):\n",
    "        f.write(generate_random_delete_query(table, primary_key, set_of_key))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd16a0",
   "metadata": {},
   "source": [
    "## Queries Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbf227",
   "metadata": {},
   "source": [
    "### Select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5deddc",
   "metadata": {},
   "source": [
    "\n",
    "**Cassandra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed75b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark SELECT\n",
    "session.set_keyspace(\"benchmarking\")\n",
    "\n",
    "select_path = \"select_primary_key_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    cassandra_times_select = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            session.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_times_select[i] = (end_time - start_time)\n",
    "\n",
    "print(cassandra_times_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd2ed0",
   "metadata": {},
   "source": [
    "**PostgreSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_path = \"select_primary_key_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    postgres_times_select = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            cursor.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        postgres_times_select[i] = (end_time - start_time)\n",
    "print(postgres_times_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288d4b9",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58901b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin = min(cassandra_times_select.min(), postgres_times_select.min())\n",
    "max_bin = max(cassandra_times_select.max(), postgres_times_select.max())\n",
    "bins = np.linspace(min_bin, max_bin, 200)  # 20 bins entre les valeurs min et max\n",
    "\n",
    "# Création de l'histogramme avec des bornes communes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cassandra_times_select, bins=bins, alpha=0.7, label='Cassandra', color='blue')\n",
    "plt.hist(postgres_times_select, bins=bins, alpha=0.7, label='PostgreSQL', color='orange')\n",
    "\n",
    "# Ajout des légendes et des titres\n",
    "plt.title('Comparison of select queries', fontsize=16)\n",
    "plt.xlabel('SGBD system', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da410d99",
   "metadata": {},
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b45fd0",
   "metadata": {},
   "source": [
    "\n",
    "**Cassandra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be92487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Update\n",
    "session.set_keyspace(\"benchmarking\")\n",
    "\n",
    "select_path = \"update_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    cassandra_times_update = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            session.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_times_update[i] = (end_time - start_time)\n",
    "print(cassandra_times_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5930ca5",
   "metadata": {},
   "source": [
    "**PostgreSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_path = \"update_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    postgres_times_update = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            cursor.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        postgres_times_update[i] = (end_time - start_time)\n",
    "print(postgres_times_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d60757",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin = min(cassandra_times_update.min(), postgres_times_update.min())\n",
    "max_bin = max(cassandra_times_update.max(), postgres_times_update.max())\n",
    "bins = np.linspace(min_bin, max_bin, 200)  # 20 bins entre les valeurs min et max\n",
    "\n",
    "# Création de l'histogramme avec des bornes communes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cassandra_times_update, bins=bins, alpha=0.7, label='Cassandra', color='blue')\n",
    "plt.hist(postgres_times_update, bins=bins, alpha=0.7, label='PostgreSQL', color='orange')\n",
    "\n",
    "# Ajout des légendes et des titres\n",
    "plt.title('Comparison of update queries', fontsize=16)\n",
    "plt.xlabel('SGBD system', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9df79",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a5c8d",
   "metadata": {},
   "source": [
    "\n",
    "**Cassandra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5cf3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark DELETE\n",
    "session.set_keyspace(\"benchmarking\")\n",
    "\n",
    "select_path = \"delete_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    cassandra_times_delete = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            session.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_times_delete[i] = (end_time - start_time)\n",
    "print(cassandra_times_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddf907",
   "metadata": {},
   "source": [
    "**PostgreSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark DELETE\n",
    "\n",
    "select_path = \"delete_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    postgres_times_delete = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            cursor.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        postgres_times_delete[i] = (end_time - start_time)\n",
    "print(postgres_times_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a1696b",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820be375",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin = min(cassandra_times_delete.min(), postgres_times_delete.min())\n",
    "max_bin = max(cassandra_times_delete.max(), postgres_times_delete.max())\n",
    "bins = np.linspace(min_bin, max_bin, 200)  # 20 bins entre les valeurs min et max\n",
    "\n",
    "# Création de l'histogramme avec des bornes communes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cassandra_times_delete, bins=bins, alpha=0.7, label='Cassandra', color='blue')\n",
    "plt.hist(postgres_times_delete, bins=bins, alpha=0.7, label='PostgreSQL', color='orange')\n",
    "\n",
    "# Ajout des légendes et des titres\n",
    "plt.title('Comparison of delete queries', fontsize=16)\n",
    "plt.xlabel('SGBD system', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d105bf01",
   "metadata": {},
   "source": [
    "### Conclusion about postgreSQL vs cassandra\n",
    "\n",
    "We observe that Cassandra is faster than PostgreSQL for all CRUD operations, especially for import where Cassandra is more than 3000 times faster. It can be explained by the fact it is presented as a write-oriented NoSQL system, especially suited for such operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd119db",
   "metadata": {},
   "source": [
    "## Index utilisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635953fd",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "\n",
    "Set up new table to benchmark effect of indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two tables to compare \n",
    "session.execute(\"\"\"CREATE TABLE IF NOT EXISTS benchmarking.bitcoin_addresses_not_indexed (BITCOIN_ADDRESS text, ACCOUNT text, \n",
    "IP_ADDRESS text, COUNTY text, COUNTRY_CODE text, DATABASE_COLUMN_TYPE text, PRIMARY KEY \n",
    "(BITCOIN_ADDRESS))\"\"\")\n",
    "session.execute(\"\"\"CREATE TABLE IF NOT EXISTS benchmarking.bitcoin_addresses_indexed (BITCOIN_ADDRESS text, ACCOUNT text, \n",
    "IP_ADDRESS text, COUNTY text, COUNTRY_CODE text, DATABASE_COLUMN_TYPE text, PRIMARY KEY \n",
    "(BITCOIN_ADDRESS))\"\"\")\n",
    "\n",
    "# Import data\n",
    "with open(\"/home/data.csv\", 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    notindexed_insert_query = session.prepare(\"\"\"\n",
    "INSERT INTO benchmarking.bitcoin_addresses_indexed (BITCOIN_ADDRESS, ACCOUNT, IP_ADDRESS, COUNTY, COUNTRY_CODE, DATABASE_COLUMN_TYPE)\n",
    "VALUES (?, ?, ?, ?, ?, ?)\n",
    "\"\"\")\n",
    "\n",
    "    batch = BatchStatement()\n",
    "\n",
    "    for row in reader:\n",
    "        session.execute(notindexed_insert_query, (\n",
    "            row['BITCOIN_ADDRESS'],\n",
    "            row['ACCOUNT'],\n",
    "            row['IP_ADDRESS'],\n",
    "            row['COUNTY'],\n",
    "            row['COUNTRY_CODE'],\n",
    "            row['DATABASE_COLUMN_TYPE']\n",
    "        ))\n",
    "\n",
    "    session.execute(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4a659e",
   "metadata": {},
   "source": [
    "**Creation of an index**\n",
    "\n",
    "`COUNTY` `COUNTRY_CODE` `DATABASE_COLUMN_TYPE` columns are selected to be indexed because they have a moderate cardinality. The indexing must have a significant effect on queries performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1cc4f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x786c2f363fa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create index\n",
    "create_index_query_county = \"\"\"CREATE INDEX IF NOT EXISTS countyindex on benchmarking.bitcoin_addresses_indexed (COUNTY)\"\"\"\n",
    "session.execute(create_index_query_county)\n",
    "create_index_query_countrycode = \"\"\"CREATE INDEX IF NOT EXISTS countrycodeindex on benchmarking.bitcoin_addresses_indexed (COUNTRY_CODE)\"\"\"\n",
    "session.execute(create_index_query_countrycode)\n",
    "create_index_query_datacolumntype = \"\"\"CREATE INDEX IF NOT EXISTS datacolumntypeindex on benchmarking.bitcoin_addresses_indexed (DATABASE_COLUMN_TYPE)\"\"\"\n",
    "session.execute(create_index_query_datacolumntype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f3658",
   "metadata": {},
   "source": [
    "**Import with indexes**\n",
    "\n",
    "Indexing impacts import performance because the database must update the index structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "with open(\"/home/data.csv\", 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    insert_query = session.prepare(\"\"\"\n",
    "INSERT INTO benchmarking.bitcoin_addresses_indexed (BITCOIN_ADDRESS, ACCOUNT, IP_ADDRESS, COUNTY, COUNTRY_CODE, DATABASE_COLUMN_TYPE)\n",
    "VALUES (?, ?, ?, ?, ?, ?)\n",
    "\"\"\")\n",
    "    cassandra_indexed_times_import = np.empty(100)\n",
    "\n",
    "    for sample in range(100):\n",
    "        batch = BatchStatement()\n",
    "\n",
    "        for i in range(1000):\n",
    "            row = next(reader)\n",
    "            session_replicate.execute(insert_query, (\n",
    "                row['BITCOIN_ADDRESS'],\n",
    "                row['ACCOUNT'],\n",
    "                row['IP_ADDRESS'],\n",
    "                row['COUNTY'],\n",
    "                row['COUNTRY_CODE'],\n",
    "                row['DATABASE_COLUMN_TYPE']\n",
    "            ))\n",
    "\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        session_replicate.execute(batch)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_indexed_times_import[sample] = (end_time - start_time)\n",
    "        print(sample, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958063cf",
   "metadata": {},
   "source": [
    "### Queries with conditions\n",
    "To evaluate the performance of indexing, we perform SELECT queries with where clause on indexed columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb42060",
   "metadata": {},
   "source": [
    "**Indexed table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f4b80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark indexed table\n",
    "session.set_keyspace(\"benchmarking\")\n",
    "\n",
    "select_path = \"select_conditions_indexed_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = len(lines)\n",
    "    cassandra_times_select_indexed = np.empty(n_iter)\n",
    "    \n",
    "    for line in lines:\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        session.execute(line)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_times_select_indexed[i] = (end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a54451",
   "metadata": {},
   "source": [
    "**Not indexed table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb33aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark not indexed table\n",
    "session.set_keyspace(\"benchmarking\")\n",
    "\n",
    "select_path = \"select_conditions_not_indexed_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = len(lines)\n",
    "    cassandra_times_select_not_indexed = np.empty(n_iter)\n",
    "    for i in range(n_iter):\n",
    "        lines[i] = f\"{lines[i][:-1]} ALLOW FILTERING\"\n",
    "    \n",
    "    for line in lines:\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        session.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_times_select_not_indexed[i] = (end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b0254-7986-4442-9a83-7f03fde9ac1c",
   "metadata": {},
   "source": [
    "**PostgreSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f481077-18f0-4a5d-847d-16f308da53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark not indexed table postgres\n",
    "\n",
    "select_path = \"select_conditions_not_indexed_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = len(lines)\n",
    "    postgres_times_select_not_indexed = np.empty(n_iter)\n",
    "    \n",
    "    for line in lines:\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        cursor.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        postgres_times_select_not_indexed[i] = (end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec10fd",
   "metadata": {},
   "source": [
    "## Replication performances benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd288596",
   "metadata": {},
   "source": [
    "**Setup replication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf96ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f25962b8f10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_replicate = Cluster(['cassandra-replicat-0'])\n",
    "session_replicate = cluster_replicate.connect()\n",
    "\n",
    "# Create keyspace with replication\n",
    "session_replicate.execute(\"\"\"CREATE KEYSPACE IF NOT EXISTS benchmarking WITH REPLICATION = \n",
    "{ 'class' : 'SimpleStrategy', 'replication_factor' : '3' }\"\"\")\n",
    "\n",
    "# Create table\n",
    "session_replicate.execute(\"\"\"CREATE TABLE IF NOT EXISTS benchmarking.bitcoin_addresses (BITCOIN_ADDRESS text, ACCOUNT text, \n",
    "IP_ADDRESS text, COUNTY text, COUNTRY_CODE text, DATABASE_COLUMN_TYPE text, PRIMARY KEY \n",
    "(BITCOIN_ADDRESS))\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e2c7a",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1499ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "with open(\"/home/data.csv\", 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    insert_query = session_replicate.prepare(\"\"\"\n",
    "INSERT INTO benchmarking.bitcoin_addresses (BITCOIN_ADDRESS, ACCOUNT, IP_ADDRESS, COUNTY, COUNTRY_CODE, DATABASE_COLUMN_TYPE)\n",
    "VALUES (?, ?, ?, ?, ?, ?)\n",
    "\"\"\")\n",
    "    cassandra_replication_times_import = np.empty(100)\n",
    "\n",
    "    for sample in range(100):\n",
    "        batch = BatchStatement()\n",
    "\n",
    "        for i in range(1000):\n",
    "            row = next(reader)\n",
    "            session_replicate.execute(insert_query, (\n",
    "                row['BITCOIN_ADDRESS'],\n",
    "                row['ACCOUNT'],\n",
    "                row['IP_ADDRESS'],\n",
    "                row['COUNTY'],\n",
    "                row['COUNTRY_CODE'],\n",
    "                row['DATABASE_COLUMN_TYPE']\n",
    "            ))\n",
    "\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        session_replicate.execute(batch)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_replication_times_import[sample] = (end_time - start_time)\n",
    "        print(sample, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be592a0",
   "metadata": {},
   "source": [
    "**SELECT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7226fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark SELECT\n",
    "session_replicate.set_keyspace(\"benchmarking\")\n",
    "\n",
    "select_path = \"select_primary_key_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    cassandra_replicate_times_select = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            session_replicate.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_replicate_times_select[i] = (end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ddd80",
   "metadata": {},
   "source": [
    "**UPDATE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620294d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark DELETE\n",
    "session_replicate.set_keyspace(\"benchmarking\")\n",
    "\n",
    "select_path = \"update_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    cassandra_replicate_times_update = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            session_replicate.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_replicate_times_update[i] = (end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca0182",
   "metadata": {},
   "source": [
    "**Delete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97538157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark DELETE\n",
    "session_replicate.set_keyspace(\"benchmarking\")\n",
    "\n",
    "select_path = \"delete_0.sql\"\n",
    "with open(select_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    n_iter = int(len(lines)/100)\n",
    "    cassandra_replicate_times_delete = np.empty(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        gc.collect()\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for j in range(100):\n",
    "            session_replicate.execute(lines[i*100 + j])\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        cassandra_replicate_times_delete[i] = (end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
